{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09b4acc4",
   "metadata": {},
   "source": [
    "# Vizugy portal scraper\n",
    "\n",
    "We start by scraping the latest available water level data from the website https://www.vizugy.hu/?mapData=VizmerceLista#mapData using the BeautifulSoup (bs4) library. This website provides information on water level measuring stations across Hungary. We extract the necessary data using the appropriate HTML selectors to ensure accuracy and reliability.\n",
    "\n",
    "Once we have the latest available data, we proceed to iterate through each link on the page to access the historical water level data for each measuring station (hourly data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c56594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import tqdm\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.sql import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970ae027",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIZUGY_WEBPAGE = 'https://www.vizugy.hu/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e784b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_DATETIME = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e595c5dd",
   "metadata": {},
   "source": [
    "Connect to target database and truncate stanging tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74911a00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "engine = create_engine( os.getenv(\"PG_URL\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fec716",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"truncate table raw_list\").execution_options(autocommit=True))\n",
    "    conn.execute(text(\"truncate table raw_hourly_data\").execution_options(autocommit=True))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787cb929",
   "metadata": {},
   "source": [
    "Get the first table from the `VizmerceLista` site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721bdc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_html(f'{VIZUGY_WEBPAGE}?mapData=VizmerceLista#mapData', extract_links=\"body\")\n",
    "df = df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bec9165",
   "metadata": {},
   "source": [
    "All columns here are tuple typed. First is the value of the cell, second is the link (if it is a link)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5b3670",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdb86cd",
   "metadata": {},
   "source": [
    "We simply split the tupe to `_val` and `_url` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3af33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if col == 'Vízmérce':\n",
    "        df[[col, f'{col}_url']] = pd.DataFrame(df[col].to_list(), index=df.index)\n",
    "    else:\n",
    "        df[col] = df[col].apply(lambda x: x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77be9b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"load_dt\"] = RUN_DATETIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1029574f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('raw_list', con=engine, if_exists='append', index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357791c2",
   "metadata": {},
   "source": [
    "This is how the link look like for a subpage (Station page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ec9cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0][\"Vízmérce_url\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa385d1f",
   "metadata": {},
   "source": [
    "Let's got through all subpage (station page) and collect the hourly table. All of this data will be available as `hourly_data`. Scraping these hundreds page took a while (5 mins or so)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79914177",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "for index, row in tqdm.tqdm(df.iterrows(), total=len(df)): \n",
    "    df2 = pd.read_html(f'{VIZUGY_WEBPAGE}{df.iloc[index][\"Vízmérce_url\"]}',parse_dates=True)\n",
    "    df2[1][\"Vízmérce\"] = df.iloc[index][\"Vízmérce\"]\n",
    "    df2[1][\"Vízfolyás\"] = df.iloc[index][\"Vízfolyás\"]\n",
    "    df2[1][\"URL\"] = df.iloc[index][\"Vízmérce_url\"]\n",
    "    df_list.append(df2[1])\n",
    "\n",
    "hourly_data = pd.concat(df_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a8dbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_data[\"load_dt\"] = RUN_DATETIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8a4583",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d99c966",
   "metadata": {},
   "source": [
    "Save to postgres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25968f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_data.to_sql('raw_hourly_data', con=engine, if_exists='append',\n",
    "           index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536caf8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece54547",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_list = \"\"\"\n",
    "MERGE INTO gauging_stations AS target\n",
    "USING (\n",
    "  SELECT\n",
    "    \"Vízmérce\" || '-' || \"Vízfolyás\" AS id,\n",
    "    \"Vízmérce\" AS gauging_station,\n",
    "    \"Vízfolyás\" AS waterflow,\n",
    "    \"Szelvény (fkm)\" AS river_km,\n",
    "    to_timestamp(\"Időpont\", 'YYYY.MM.DD. HH24:MI') AS measure_date,\n",
    "    \"Vízmérce_url\" AS vizallas_url,\n",
    "    CASE WHEN \"Vízállás (cm)\" = '' THEN NULL ELSE \"Vízállás (cm)\"::float END as water_level,\n",
    "    load_dt\n",
    "  FROM\n",
    "    raw_list\n",
    ") AS source\n",
    "ON (target.id = source.id)\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET\n",
    "    gauging_station = source.gauging_station,\n",
    "    waterflow = source.waterflow,\n",
    "    river_km = source.river_km,\n",
    "    measure_date = source.measure_date,\n",
    "    vizallas_url = source.vizallas_url,\n",
    "    water_level = source.water_level,\n",
    "    load_dt = source.load_dt\n",
    "WHEN NOT MATCHED THEN\n",
    "  INSERT (id, gauging_station, waterflow, river_km, measure_date, vizallas_url, water_level, load_dt)\n",
    "  VALUES (source.id, source.gauging_station, source.waterflow, source.river_km, source.measure_date, source.vizallas_url, source.water_level, source.load_dt)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bf6ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_hourly_data = \"\"\"\n",
    "\n",
    " MERGE INTO hourly_data AS target\n",
    "USING (\n",
    "  SELECT\n",
    "    \"Vízmérce\" || '-' ||  \"Vízfolyás\" || '-' ||\"Időpont\" id,\n",
    "    \"Vízmérce\" || '-' || \"Vízfolyás\" AS gauging_station_id,\n",
    "    \"Vízmérce\" AS gauging_station,\n",
    "    \"Vízfolyás\" AS waterflow,\n",
    "    to_timestamp(\"Időpont\", 'YYYY.MM.DD. HH24:MI') AS measure_date,\n",
    "    \"Vízállás (cm)\" AS water_level,\n",
    "    \"Vízhozam (m3/s)\" AS water_discharge,\n",
    "    load_dt\n",
    "  FROM\n",
    "    raw_hourly_data\n",
    ") AS source\n",
    "ON (target.id = source.id)\n",
    "WHEN MATCHED AND COALESCE(target.water_level,-9999) <> COALESCE(source.water_level,-9999) OR  \n",
    "                 COALESCE(target.water_discharge,-9999) <> COALESCE(source.water_discharge,-9999)\n",
    "  THEN\n",
    "  UPDATE SET\n",
    "    gauging_station = source.gauging_station,\n",
    "    gauging_station_id = source.gauging_station_id,\n",
    "    waterflow = source.waterflow,\n",
    "    measure_date = source.measure_date,\n",
    "    water_level = source.water_level,\n",
    "    water_discharge = source.water_discharge,\n",
    "    load_dt = source.load_dt\n",
    "WHEN NOT MATCHED THEN\n",
    "  INSERT (id, gauging_station_id, gauging_station, waterflow, measure_date, water_level, water_discharge, load_dt)\n",
    "  VALUES (source.id, source.gauging_station_id, source.gauging_station, source.waterflow, source.measure_date, source.water_level, source.water_discharge, source.load_dt)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420591d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.execute(text(merge_list).execution_options(autocommit=True))\n",
    "    conn.execute(text(merge_hourly_data).execution_options(autocommit=True))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e72ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
